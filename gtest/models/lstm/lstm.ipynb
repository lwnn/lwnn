{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../../../tools'))\n",
    "import numpy as np\n",
    "from verifyoutput import *\n",
    "from lwnn2torch import *\n",
    "from tf2lwnn import *\n",
    "import onnx\n",
    "import onnxruntime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEMO_MODEL='Basic_LSTM_S.pb'\n",
    "DEMO_INPUT='/mnt/d/tmp/speech_dataset/yes/0a9f9af7_nohash_1.wav'\n",
    "LABELS=['_silence_','_unknown_','yes','no','up','down','left','right','on','off','stop','go']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_data = np.fromfile(DEMO_INPUT, np.int8).reshape(1, -1)\n",
    "converter = TfConverter(DEMO_MODEL, 'KWS', {'wav_data': wav_data})\n",
    "lwnn_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in lwnn_model:\n",
    "    print(layer)\n",
    "    if(layer.op == 'LSTM'):\n",
    "        lstm_layer = layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itensor = converter.tensors['wav_data']\n",
    "otensor = converter.tensors['labels_softmax']\n",
    "lstm_i = converter.tensors['LSTM-Layer/lstm/transpose']\n",
    "lstm_o = converter.tensors['LSTM-Layer/lstm/rnn/while/Exit_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result, lstm_i_result, lstm_o_result = converter.sess.run([otensor, lstm_i, lstm_o], {itensor: wav_data.tobytes() })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_i_result.shape, lstm_o_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in converter.onnx_model.graph.node:\n",
    "    if(node.op_type == 'LSTM'):\n",
    "        lstm_node = node\n",
    "    if(node.op_type == 'Squeeze'):\n",
    "        sq_node = node\n",
    "lstm_node, sq_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = onnx.helper.make_tensor_value_info(lstm_node.input[0], onnx.TensorProto.FLOAT, lstm_i_result.shape)\n",
    "attrs = {}\n",
    "for attr in lstm_node.attribute:\n",
    "    v = onnx.helper.get_attribute_value(attr)\n",
    "    attrs[attr.name] = v\n",
    "node = onnx.helper.make_node(\n",
    "            'LSTM',\n",
    "            name = lstm_node.name,\n",
    "            inputs=lstm_node.input[:4],\n",
    "            outputs=lstm_node.output,\n",
    "            **attrs)\n",
    "outputs = [onnx.helper.make_tensor_value_info(o, onnx.TensorProto.FLOAT, None) for o in sq_node.output]\n",
    "outputs.extend([onnx.helper.make_tensor_value_info(o, onnx.TensorProto.FLOAT, None) for o in node.output])\n",
    "graph = onnx.helper.make_graph(\n",
    "            nodes = [node, sq_node],\n",
    "            name = 'LSTM',\n",
    "            inputs = [x],\n",
    "            outputs = outputs,\n",
    "            value_info = [],\n",
    "            initializer = converter.onnx_model.graph.initializer)\n",
    "model = onnx.helper.make_model(graph, producer_name='lwnn-nhwc')\n",
    "onnx.save(model, '.tmp.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = onnxruntime.InferenceSession('.tmp.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = sess.run(None, {lstm_node.input[0]: lstm_i_result })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare(lstm_o_result, rs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lstm_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W,R,B=lstm_layer.W, lstm_layer.R, lstm_layer.B\n",
    "print(W.shape, R.shape, B.shape)\n",
    "Wi,Wo,Wf,Wc = W.reshape(4,-1,10)\n",
    "print(Wi.shape, Wo.shape ,Wf.shape, Wc.shape)\n",
    "Ri,Ro,Rf,Rc = R.reshape(4,-1,118)\n",
    "print(Ri.shape, Ro.shape ,Rf.shape, Rc.shape)\n",
    "Wbi,Wbo,Wbf,Wbc,Rbi,Rbo,Rbf,Rbc = B.reshape(8, -1)\n",
    "print(Wbi.shape, Wbo.shape ,Wbf.shape, Wbc.shape, Rbi.shape, Rbo.shape ,Rbf.shape, Rbc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kerenl = converter.tensors['lstm/rnn/basic_lstm_cell/kernel/read']\n",
    "bias = converter.tensors['lstm/rnn/basic_lstm_cell/bias/read']\n",
    "print(kerenl.shape, bias.shape)\n",
    "w, b = converter.sess.run((kerenl,bias))\n",
    "w, r = w[:10, :], w[10:, :]\n",
    "w = w.transpose(1,0)\n",
    "r = r.transpose(1,0)\n",
    "print(w.shape, r.shape, b.shape)\n",
    "wi,wc,wf,wo = w.reshape(4,-1,10)\n",
    "print(wi.shape, wo.shape ,wf.shape, wc.shape)\n",
    "ri,rc,rf,ro = r.reshape(4,-1,118)\n",
    "print(ri.shape, ro.shape ,rf.shape, rc.shape)\n",
    "wbi,wbc,wbf,wbo = b.reshape(4, -1)\n",
    "print(wbi.shape, wbo.shape ,wbf.shape, wbc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare(Wi, wi, 'wi')\n",
    "compare(Wf, wf, 'wf')\n",
    "compare(Wo, wo, 'wo')\n",
    "compare(Wc, wc, 'wc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare(Ri, ri, 'ri')\n",
    "compare(Rf, rf, 'rf')\n",
    "compare(Ro, ro, 'ro')\n",
    "compare(Rc, rc, 'rc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare(Wbi, wbi, 'wbi')\n",
    "compare(Wbf, wbf, 'wbf')\n",
    "compare(Wbo, wbo, 'wbo')\n",
    "compare(Wbc, wbc, 'wbc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/onnx/onnx/blob/master/docs/Operators.md#LSTM\n",
    "\n",
    "http://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "\n",
    "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/rnn/lstm_ops.cc\n",
    "\n",
    "Equations (Default: f=Sigmoid, g=Tanh, h=Tanh):\n",
    "\n",
    "```python\n",
    " it = f(Xt*(Wi^T) + Ht-1*(Ri^T) + Pi (.) Ct-1 + Wbi + Rbi)\n",
    " ft = f(Xt*(Wf^T) + Ht-1*(Rf^T) + Pf (.) Ct-1 + Wbf + Rbf)\n",
    " ct = g(Xt*(Wc^T) + Ht-1*(Rc^T) + Wbc + Rbc)\n",
    " Ct = ft (.) Ct-1 + it (.) ct\n",
    " ot = f(Xt*(Wo^T) + Ht-1*(Ro^T) + Po (.) Ct + Wbo + Rbo)\n",
    " Ht = ot (.) h(Ct)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "c = np.zeros((1,118))\n",
    "h = np.zeros((1,118))\n",
    "for x in np.split(lstm_i_result, lstm_i_result.shape[0], axis=0):\n",
    "    it = sigmoid( np.dot(x, Wi.transpose()) + np.dot(h, Ri.transpose()) + Wbi + Rbi )\n",
    "    ft = sigmoid( np.dot(x, Wf.transpose()) + np.dot(h, Rf.transpose()) + Wbf + Rbf )\n",
    "    ct = np.tanh( np.dot(x, Wc.transpose()) + np.dot(h, Rc.transpose()) + Wbc + Rbc )\n",
    "    Ct = ft*c + it*ct\n",
    "    ot = sigmoid( np.dot(x, Wo.transpose()) + np.dot(h, Ro.transpose()) + Wbo + Rbo )\n",
    "    Ht = ot*np.tanh(Ct)\n",
    "    c = Ct\n",
    "    h = Ht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare(lstm_o_result, Ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnx.backend.test.case.node.lstm import LSTM_Helper\n",
    "lstm = LSTM_Helper(X=lstm_i_result, W=W, R=R, B=B)\n",
    "Y, Y_h = lstm.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare(lstm_o_result, Y_h)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
